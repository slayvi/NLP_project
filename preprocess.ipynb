{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data Step 1\n",
    "__________________________\n",
    "\n",
    "Preparing the overall data for later classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading essential Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "import os \n",
    "import shutil\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Dataset, create directionaries, remove unsupervised directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "dataset = tf.keras.utils.get_file(\"aclImdb_v1.tar.gz\", url, untar=True, cache_subdir=\"./\", cache_dir=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imdb.vocab', 'imdbEr.txt', 'README', 'test', 'train']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dir = os.path.join(os.path.dirname(dataset), \"aclImdb\")\n",
    "os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labeledBow.feat',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'unsup',\n",
       " 'unsupBow.feat',\n",
       " 'urls_neg.txt',\n",
       " 'urls_pos.txt',\n",
       " 'urls_unsup.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = os.path.join(\"aclImdb\"+\"/\",\"train\" )\n",
    "os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dir = os.path.join(train_dir, \"unsup\")\n",
    "shutil.rmtree(remove_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the Text Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize spacy basics, prepare stop word list, convert it to set (improved computation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import re \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stop_words.remove(\"not\")\n",
    "stop_words.remove(\"nor\")\n",
    "stop_words.remove(\"no\")\n",
    "stop_words.remove(\"again\")\n",
    "add_stopwords  = set([\"movie\", \"film\", \"one\", \"the\", \"scene\", \"this\", \"story\", \"would\", \"really\", \"and\", \"also\", ])\n",
    "\n",
    "stop_words = stop_words.union(add_stopwords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove html tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(text):\n",
    "    text = re.sub(r\"<[\\w]+ />\", \" \", text)\n",
    "    text = re.sub(\"n't\", \" not\", text)\n",
    "    return text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean text in general, stopwords removal and lemmatizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\b\\w{1,1}\\b\", \" \", text)                                                     # remove single characters\n",
    "    text = re.sub(r\"[^a-z]\", \" \", text)                                                          # remove everything which aren't letters\n",
    "    text = re.sub(r\"[\\s]+\", \" \", text)                                                           # remove too many whitespaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove PERSON tokens and Stop words:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_filter_non_entities(text):\n",
    "    doc = nlp(text)\n",
    "    non_entity_lemmas = [token.lemma_ for token in doc if token.ent_type_ != \"PERSON\"]\n",
    "    non_entity_lemmas = [token for token in non_entity_lemmas if token.lower() not in stop_words]\n",
    "    text = \" \".join(non_entity_lemmas) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply preprocessing steps on text files and save the files in new directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "def process_files_in_directory(input_directory, output_directory):\n",
    "    for root, dirs, files in os.walk(input_directory):\n",
    "        for file in files:\n",
    "            input_file_path = os.path.join(root, file)\n",
    "            with open(input_file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "\n",
    "            text_removed_html = remove_html(content)\n",
    "            text_removed_ents = process_and_filter_non_entities(text_removed_html)\n",
    "            processed_content = clean_text(text_removed_ents)\n",
    "\n",
    "            # Create the output directory if it doesn't exist\n",
    "            output_subdirectory = os.path.join(output_directory, os.path.relpath(root, input_directory))\n",
    "            os.makedirs(output_subdirectory, exist_ok=True)\n",
    "\n",
    "            # Save the processed content to a new file in the output directory\n",
    "            output_file_path = os.path.join(output_subdirectory, file)\n",
    "            with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(processed_content)\n",
    "\n",
    "input_pos_directory = './aclImdb/train/pos'\n",
    "input_neg_directory = './aclImdb/train/neg'\n",
    "\n",
    "output_pos_directory = './dataset/train/pre_final/pos'\n",
    "output_neg_directory = './dataset/train/pre_final/neg'\n",
    "\n",
    "process_files_in_directory(input_pos_directory, output_pos_directory)\n",
    "process_files_in_directory(input_neg_directory, output_neg_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "repeat last step with training and testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data Step 2\n",
    "__________________________\n",
    "\n",
    "For easier working with scikit-learn algorithms, the text files will be converted into .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directories containing text files\n",
    "input_directory_pos = \"./dataset/test/pre_final/pos\"\n",
    "input_directory_neg = \"./dataset/test/pre_final/neg\"\n",
    "\n",
    "# Output CSV file\n",
    "output_csv_file = \"./dataset/testing_set_preprocessed.csv\"\n",
    "\n",
    "# Function to process each text file\n",
    "def process_text_file(file_path, label):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "        new_column_value = label\n",
    "        return content, new_column_value\n",
    "\n",
    "data_list = []\n",
    "\n",
    "# Process \"positive\" directory\n",
    "for filename in os.listdir(input_directory_pos):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(input_directory_pos, filename)\n",
    "        content, new_column_value = process_text_file(file_path, \"pos\")\n",
    "        data_list.append([content, new_column_value])\n",
    "\n",
    "# Process \"negative\" directory\n",
    "for filename in os.listdir(input_directory_neg):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(input_directory_neg, filename)\n",
    "        content, new_column_value = process_text_file(file_path, \"neg\")\n",
    "        data_list.append([content, new_column_value])\n",
    "\n",
    "# CSV headers\n",
    "csv_headers = [\"review\", \"sentiment\"]\n",
    "\n",
    "df = pd.DataFrame(data_list, columns=csv_headers)\n",
    "df.to_csv(output_csv_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go see last night coax friend mine ll admit re...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actor turn director follow promising debut got...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recreational golfer knowledge sport history pl...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>see sneak preview delightful cinematography un...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>take true us golf open make much extra ordinar...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>occasionally let kid watch garbage understand ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>anymore pretty much reality tv show people mak...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>basic genre thriller intercut uncomfortable me...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>four thing intrigue firstly star carly pope po...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>comment nearby exceptionally well write inform...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      go see last night coax friend mine ll admit re...       pos\n",
       "1      actor turn director follow promising debut got...       pos\n",
       "2      recreational golfer knowledge sport history pl...       pos\n",
       "3      see sneak preview delightful cinematography un...       pos\n",
       "4      take true us golf open make much extra ordinar...       pos\n",
       "...                                                  ...       ...\n",
       "24995  occasionally let kid watch garbage understand ...       neg\n",
       "24996  anymore pretty much reality tv show people mak...       neg\n",
       "24997  basic genre thriller intercut uncomfortable me...       neg\n",
       "24998  four thing intrigue firstly star carly pope po...       neg\n",
       "24999  comment nearby exceptionally well write inform...       neg\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(output_csv_file)\n",
    "data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "repeat the same procedure for training and testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data Step 3\n",
    "__________________________\n",
    "\n",
    "This is one leftover from preparing the preprocessing steps: visualizing the Named Entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">go see \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    last night\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       " coax friend mine ll admit reluctant see know able comedy wrong kutcher play character well play professionalism sign good toy emotion exactly entire theater sell overcome laughter \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    first\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    half\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " move tear \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    second\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " half exit theater not see many woman tear many full grown man well try desperately not let anyone see cry great suggest go see judge </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from pathlib import Path\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def process_and_filter_entities(text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    colors = {'PERSON': 'cyan'}\n",
    "    options = {'colors': colors}\n",
    "\n",
    "    displacy.render(doc, style=\"ent\", options=options, page=False)\n",
    "\n",
    "text_to_visualize = data[\"review\"][0]\n",
    "\n",
    "process_and_filter_entities(text_to_visualize)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfnlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
